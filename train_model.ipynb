{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.sparse import diags\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import bisect\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import time\n",
        "import tqdm\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import (\n",
        "    CReLU,\n",
        "    Identity,\n",
        "    ComplexInstanceNorm2d,\n",
        "    ComplexConv2d,\n",
        "    ComplexConv1d,\n",
        "    SpectralConv2d,\n",
        "    SpectralConv2d_Complex,\n",
        "    MLP,\n",
        "    MLP1d,\n",
        "    FourierLayer,\n",
        "    FNO2d\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ql_n5PWXPR5"
      },
      "outputs": [],
      "source": [
        "def move_to_cuda(sample, device=None):\n",
        "    if len(sample) == 0:\n",
        "        return {}\n",
        "\n",
        "    def _move_to_cuda(maybe_tensor,device):\n",
        "        if torch.is_tensor(maybe_tensor):\n",
        "            return maybe_tensor.to(device)\n",
        "        elif isinstance(maybe_tensor, dict):\n",
        "            return {key: _move_to_cuda(value,device) for key, value in maybe_tensor.items()}\n",
        "        elif isinstance(maybe_tensor, list):\n",
        "            return [_move_to_cuda(x,device) for x in maybe_tensor]\n",
        "        elif isinstance(maybe_tensor, tuple):\n",
        "            return [_move_to_cuda(x,device) for x in maybe_tensor]\n",
        "        else:\n",
        "            return maybe_tensor\n",
        "\n",
        "    return _move_to_cuda(sample,device)\n",
        "\n",
        "# def\n",
        "\n",
        "def collate_fn(batch_data):\n",
        "    inputs = []\n",
        "    eig_vecs = []\n",
        "\n",
        "    for _,data in enumerate(batch_data):\n",
        "        inputs.append(data['input'])\n",
        "        eig_vecs.append(data['eig_vec'])\n",
        "\n",
        "    return {'inputs':torch.cat(inputs,dim=0),\n",
        "            'eig_vecs':torch.cat(eig_vecs,dim=0)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx_JRSeZ2jiY"
      },
      "outputs": [],
      "source": [
        "class mat_dataset(Dataset):\n",
        "    def __init__(self, index_path, k, channel_dim=3, cache_size=4):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.channel_dim = channel_dim\n",
        "\n",
        "        # читаем метаданные из json (быстро)\n",
        "        with open(index_path, \"r\") as f:\n",
        "            index = json.load(f)\n",
        "        self.path_list = index[\"paths\"]\n",
        "        self.file_sizes = index[\"sizes\"]\n",
        "\n",
        "        # кумулятивные суммы как обычный python-список\n",
        "        self.cum_sizes = []\n",
        "        s = 0\n",
        "        for sz in self.file_sizes:\n",
        "            s += sz\n",
        "            self.cum_sizes.append(s)\n",
        "        self.total_len = self.cum_sizes[-1]\n",
        "\n",
        "        # LRU-кэш\n",
        "        self.cache = OrderedDict()\n",
        "        self.cache_size = cache_size\n",
        "\n",
        "    def _load_file(self, path):\n",
        "        if path in self.cache:\n",
        "            self.cache.move_to_end(path)\n",
        "            return self.cache[path]\n",
        "\n",
        "        data = torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "        if len(self.cache) >= self.cache_size:\n",
        "            self.cache.popitem(last=False)\n",
        "\n",
        "        self.cache[path] = data\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Находим file_idx через bisect вместо .nonzero()\n",
        "        # self.cum_sizes — монотонно возрастающий список\n",
        "        file_idx = bisect.bisect_right(self.cum_sizes, index)\n",
        "        # bisect_right вернёт позицию, поэтому индекс файла = file_idx\n",
        "        # но index — 0-based, а cum_sizes — как [n0, n0+n1, ...]\n",
        "        # Например, index=0..n0-1 → file_idx=0\n",
        "\n",
        "        # аккуратно вычисляем локальный индекс\n",
        "        if file_idx == 0:\n",
        "            local_index = index\n",
        "        else:\n",
        "            local_index = index - self.cum_sizes[file_idx - 1]\n",
        "\n",
        "        data = self._load_file(self.path_list[file_idx])\n",
        "\n",
        "        x = data['params'][local_index]\n",
        "        eig_vecs = data['eig_vecs'][local_index]\n",
        "\n",
        "        if self.channel_dim is not None and self.channel_dim >= 0:\n",
        "            # на всякий случай проверка размерности\n",
        "            if self.channel_dim <= x.dim():\n",
        "                x = x.unsqueeze(self.channel_dim)\n",
        "            else:\n",
        "                # если что-то не так, лучше явно упасть, чем тихо сломать форму\n",
        "                raise ValueError(\n",
        "                    f\"channel_dim={self.channel_dim} is out of range for x.dim()={x.dim()}\"\n",
        "                )\n",
        "\n",
        "        if self.k > 0:\n",
        "            eig_vecs = eig_vecs[..., :self.k]\n",
        "\n",
        "        # Я БЫ советовал здесь не делать unsqueeze(0), а оставить\n",
        "        # это DataLoader’у, но если у тебя остальной код завязан на\n",
        "        # эту форму – можно временно оставить как есть:\n",
        "        return {\n",
        "            'input': x.unsqueeze(0),\n",
        "            'eig_vec': eig_vecs.unsqueeze(0)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n5iGad-XUrR"
      },
      "outputs": [],
      "source": [
        "class ProjectionLoss(nn.Module):\n",
        "    def __init__(self,num_type='real',reduction='mean',p=2, dim=1):\n",
        "        super(ProjectionLoss,self).__init__()\n",
        "        self.num_type = num_type\n",
        "        self.reduction = reduction\n",
        "        self.p=p\n",
        "        self.dim=dim\n",
        "\n",
        "        if self.num_type == 'complex':\n",
        "            self.trans = torch.adjoint\n",
        "        else:\n",
        "            self.trans = torch.transpose\n",
        "\n",
        "    def forward(self,Q,V):\n",
        "        \"\"\"\n",
        "        Q: [batch_size,dim,k]\n",
        "        V: [batch_size,dim,K] # K > k\n",
        "        caculate sum(V-Q@Q*V)\n",
        "        \"\"\"\n",
        "\n",
        "        assert Q.shape[-2] == V.shape[-2], f\"Shape error! Q shape [{Q.shape[-2]}] must match V shape [{V.shape[-2]}] in dimension -2\"\n",
        "\n",
        "        Qt = self.trans(Q,-2,-1)\n",
        "        QtV = torch.bmm(Qt,V)\n",
        "        QQtV = torch.bmm(Q,QtV)\n",
        "\n",
        "        result = V - QQtV\n",
        "        norm = torch.norm(result,p=self.p,dim=self.dim)\n",
        "\n",
        "        loss = torch.sum(norm,dim=-1)\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            result = torch.mean(loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            result = torch.sum(loss)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "class PrincipalAngle(nn.Module):\n",
        "    \"\"\"\n",
        "    Caculate the angle between two subspace.\n",
        "    type[Option]: biggest or smallest angle between two subspace\n",
        "    \"\"\"\n",
        "    def __init__(self, angle_type='biggest', reduction = 'mean', clip_value=True):\n",
        "        super(PrincipalAngle,self).__init__()\n",
        "        self.angle_type = angle_type\n",
        "        self.reduction = reduction\n",
        "        self.clip_value = clip_value\n",
        "        self.compare = torch.max if self.angle_type == 'biggest' else torch.min\n",
        "\n",
        "    def forward(self,Q,V):\n",
        "        \"\"\"\n",
        "        Q,V: base vectors which make up the subspace\n",
        "        \"\"\"\n",
        "\n",
        "        _, values, _ = torch.linalg.svd(torch.bmm(torch.transpose(Q,-2,-1),V))\n",
        "\n",
        "        if self.clip_value:\n",
        "            values = torch.clamp(values,min=-1,max=1)\n",
        "\n",
        "        angles = torch.acos(values)\n",
        "\n",
        "        angle,_ = self.compare(angles,dim=-1)\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            result = torch.mean(angle)\n",
        "        elif self.reduction == 'sum':\n",
        "            result = torch.sum(angle)\n",
        "        else:\n",
        "            result = angle\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUOOc4UXa7E",
        "outputId": "2573797d-d177-4c9e-c345-3f7b91eda712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import time, os, shutil\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path for .pt file data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7I0jVNicxwB"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/heat_backup'\n",
        "files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.startswith('heat_batch_') and f.endswith('.pt')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HDX8IESvOUBZ"
      },
      "outputs": [],
      "source": [
        "divide_step = int(len(files) / 5 * 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGxV7Qix2VpC"
      },
      "outputs": [],
      "source": [
        "def build_index(path_list, index_path=\"sizes_index.json\"):\n",
        "    file_sizes = []\n",
        "    for path in path_list:\n",
        "        data = torch.load(path, map_location=\"cpu\")\n",
        "        # предполагаем, что data['params'] есть в каждом файле\n",
        "        file_sizes.append(data['params'].shape[0])\n",
        "        del data\n",
        "    index = {\n",
        "        \"paths\": path_list,\n",
        "        \"sizes\": file_sizes\n",
        "    }\n",
        "    with open(index_path, \"w\") as f:\n",
        "        json.dump(index, f)\n",
        "    print(f\"Saved index to {index_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4iMfMnjH-CH"
      },
      "outputs": [],
      "source": [
        "# Files for train, valid and test (sample)\n",
        "\n",
        "train_index = \"train_sizes_index_10.json\"\n",
        "valid_index = \"valid_sizes_index_10.json\"\n",
        "test_index = \"test_sizes_index_10.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESWG4Hjh3JRg",
        "outputId": "beac3a90-ded4-470e-f798-2e3fa65263cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******************** DATA LOADING ********************\n"
          ]
        }
      ],
      "source": [
        "SAVE_PATH = './results/'\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.mkdir(SAVE_PATH)\n",
        "\n",
        "r = 300\n",
        "width = 10\n",
        "modes1 = 8\n",
        "modes2 = 8\n",
        "in_channel_size = 2\n",
        "out_size = (r)**2\n",
        "num_layers = 5\n",
        "norm = True\n",
        "COMPLEX = False\n",
        "grid = True\n",
        "num_type = 'complex' if COMPLEX else 'real'\n",
        "\n",
        "k = 25\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "print(\"*\"*20+\" DATA LOADING \"+\"*\"*20)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    mat_dataset(index_path=train_index, k=k, cache_size=8),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    pin_memory=False,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    mat_dataset(index_path=valid_index, k=k, cache_size=8),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=False,\n",
        "    pin_memory=False,\n",
        "    collate_fn=collate_fn,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw47ghw34rw9",
        "outputId": "a041d591-a1a3-411b-f70f-2cbce5eb0e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******************** TRAINING С ГИБРИДНОЙ LOSS ********************\n",
            "Конфигурация: width=20, modes=12x12, layers=5\n",
            "Loss: ProjectionLoss + 10.0 * AngleLoss\n",
            "Data: 40 train batches, 7 val batches\n",
            "\n",
            "Epoch   0 | Train: angle=1.1797 proj=9.52 | Val: angle=1.0508 proj=6.25 | LR=0.005000\n",
            "    ✓ Saved best model (val_angle=1.0508)\n",
            "Epoch   1 | Train: angle=1.0012 proj=5.29 | Val: angle=0.9981 proj=4.76 | LR=0.004999\n",
            "    ✓ Saved best model (val_angle=0.9981)\n",
            "Epoch   2 | Train: angle=0.9661 proj=4.38 | Val: angle=0.9534 proj=4.19 | LR=0.004997\n",
            "    ✓ Saved best model (val_angle=0.9534)\n",
            "Epoch   3 | Train: angle=0.8545 proj=3.97 | Val: angle=0.7762 proj=3.69 | LR=0.004995\n",
            "    ✓ Saved best model (val_angle=0.7762)\n",
            "Epoch   4 | Train: angle=0.6914 proj=3.39 | Val: angle=0.6928 proj=3.14 | LR=0.004992\n",
            "    ✓ Saved best model (val_angle=0.6928)\n",
            "Epoch   5 | Train: angle=0.6290 proj=3.00 | Val: angle=0.6532 proj=2.95 | LR=0.004989\n",
            "    ✓ Saved best model (val_angle=0.6532)\n",
            "Epoch   6 | Train: angle=0.5790 proj=2.80 | Val: angle=0.6263 proj=2.68 | LR=0.004985\n",
            "    ✓ Saved best model (val_angle=0.6263)\n",
            "Epoch   7 | Train: angle=0.5291 proj=2.52 | Val: angle=0.6051 proj=2.52 | LR=0.004980\n",
            "    ✓ Saved best model (val_angle=0.6051)\n",
            "Epoch   8 | Train: angle=0.5084 proj=2.49 | Val: angle=0.5985 proj=2.49 | LR=0.004975\n",
            "    ✓ Saved best model (val_angle=0.5985)\n",
            "Epoch   9 | Train: angle=0.4574 proj=2.31 | Val: angle=0.5797 proj=2.38 | LR=0.004969\n",
            "    ✓ Saved best model (val_angle=0.5797)\n",
            "Epoch  10 | Train: angle=0.4131 proj=2.25 | Val: angle=0.5718 proj=2.34 | LR=0.004963\n",
            "    ✓ Saved best model (val_angle=0.5718)\n",
            "Epoch  11 | Train: angle=0.3720 proj=2.19 | Val: angle=0.5622 proj=2.27 | LR=0.004956\n",
            "    ✓ Saved best model (val_angle=0.5622)\n",
            "Epoch  12 | Train: angle=0.3303 proj=2.08 | Val: angle=0.5651 proj=2.25 | LR=0.004948\n",
            "Epoch  13 | Train: angle=0.2926 proj=1.94 | Val: angle=0.5475 proj=2.12 | LR=0.004940\n",
            "    ✓ Saved best model (val_angle=0.5475)\n",
            "Epoch  14 | Train: angle=0.2785 proj=1.90 | Val: angle=0.5406 proj=2.13 | LR=0.004931\n",
            "    ✓ Saved best model (val_angle=0.5406)\n",
            "Epoch  15 | Train: angle=0.2567 proj=1.82 | Val: angle=0.5421 proj=2.09 | LR=0.004921\n",
            "Epoch  16 | Train: angle=0.2381 proj=1.77 | Val: angle=0.5434 proj=2.07 | LR=0.004911\n",
            "Epoch  17 | Train: angle=0.2271 proj=1.72 | Val: angle=0.5245 proj=1.98 | LR=0.004901\n",
            "    ✓ Saved best model (val_angle=0.5245)\n",
            "Epoch  18 | Train: angle=0.2084 proj=1.64 | Val: angle=0.5269 proj=1.92 | LR=0.004889\n",
            "Epoch  19 | Train: angle=0.1999 proj=1.59 | Val: angle=0.5192 proj=1.89 | LR=0.004878\n",
            "    ✓ Saved best model (val_angle=0.5192)\n",
            "Epoch  20 | Train: angle=0.1951 proj=1.53 | Val: angle=0.5230 proj=1.92 | LR=0.004865\n",
            "Epoch  21 | Train: angle=0.2041 proj=1.58 | Val: angle=0.5192 proj=1.91 | LR=0.004852\n",
            "Epoch  22 | Train: angle=0.1831 proj=1.50 | Val: angle=0.5195 proj=1.84 | LR=0.004839\n",
            "Epoch  23 | Train: angle=0.1800 proj=1.48 | Val: angle=0.5127 proj=1.83 | LR=0.004824\n",
            "    ✓ Saved best model (val_angle=0.5127)\n",
            "Epoch  24 | Train: angle=0.1851 proj=1.47 | Val: angle=0.5138 proj=1.84 | LR=0.004810\n",
            "Epoch  25 | Train: angle=0.1828 proj=1.46 | Val: angle=0.5065 proj=1.78 | LR=0.004794\n",
            "    ✓ Saved best model (val_angle=0.5065)\n",
            "Epoch  26 | Train: angle=0.1721 proj=1.40 | Val: angle=0.5087 proj=1.78 | LR=0.004779\n",
            "Epoch  27 | Train: angle=0.1752 proj=1.41 | Val: angle=0.5131 proj=1.76 | LR=0.004762\n",
            "Epoch  28 | Train: angle=0.1647 proj=1.36 | Val: angle=0.5096 proj=1.74 | LR=0.004745\n",
            "Epoch  29 | Train: angle=0.1707 proj=1.36 | Val: angle=0.5109 proj=1.76 | LR=0.004728\n",
            "Epoch  30 | Train: angle=0.1665 proj=1.34 | Val: angle=0.5089 proj=1.76 | LR=0.004709\n",
            "Epoch  31 | Train: angle=0.1680 proj=1.34 | Val: angle=0.5067 proj=1.72 | LR=0.004691\n",
            "Epoch  32 | Train: angle=0.1598 proj=1.32 | Val: angle=0.5008 proj=1.70 | LR=0.004672\n",
            "    ✓ Saved best model (val_angle=0.5008)\n",
            "Epoch  33 | Train: angle=0.1485 proj=1.27 | Val: angle=0.5042 proj=1.71 | LR=0.004652\n",
            "Epoch  34 | Train: angle=0.1406 proj=1.23 | Val: angle=0.5124 proj=1.66 | LR=0.004632\n",
            "Epoch  35 | Train: angle=0.1494 proj=1.25 | Val: angle=0.4998 proj=1.67 | LR=0.004611\n",
            "    ✓ Saved best model (val_angle=0.4998)\n",
            "Epoch  36 | Train: angle=0.1507 proj=1.27 | Val: angle=0.5061 proj=1.68 | LR=0.004590\n",
            "Epoch  37 | Train: angle=0.1450 proj=1.23 | Val: angle=0.4984 proj=1.68 | LR=0.004568\n",
            "    ✓ Saved best model (val_angle=0.4984)\n",
            "Epoch  38 | Train: angle=0.1341 proj=1.19 | Val: angle=0.5003 proj=1.57 | LR=0.004545\n",
            "Epoch  39 | Train: angle=0.1321 proj=1.17 | Val: angle=0.5064 proj=1.66 | LR=0.004523\n",
            "Epoch  40 | Train: angle=0.1361 proj=1.18 | Val: angle=0.4939 proj=1.61 | LR=0.004499\n",
            "    ✓ Saved best model (val_angle=0.4939)\n",
            "Epoch  41 | Train: angle=0.1308 proj=1.13 | Val: angle=0.5071 proj=1.66 | LR=0.004475\n",
            "Epoch  42 | Train: angle=0.1377 proj=1.16 | Val: angle=0.4996 proj=1.61 | LR=0.004451\n",
            "Epoch  43 | Train: angle=0.1423 proj=1.18 | Val: angle=0.4948 proj=1.60 | LR=0.004426\n",
            "Epoch  44 | Train: angle=0.1333 proj=1.14 | Val: angle=0.4915 proj=1.56 | LR=0.004401\n",
            "    ✓ Saved best model (val_angle=0.4915)\n",
            "Epoch  45 | Train: angle=0.1284 proj=1.12 | Val: angle=0.4972 proj=1.59 | LR=0.004375\n",
            "Epoch  46 | Train: angle=0.1260 proj=1.11 | Val: angle=0.4925 proj=1.59 | LR=0.004349\n",
            "Epoch  47 | Train: angle=0.1182 proj=1.08 | Val: angle=0.4902 proj=1.53 | LR=0.004322\n",
            "    ✓ Saved best model (val_angle=0.4902)\n",
            "Epoch  48 | Train: angle=0.1109 proj=1.04 | Val: angle=0.4911 proj=1.51 | LR=0.004295\n",
            "Epoch  49 | Train: angle=0.1152 proj=1.05 | Val: angle=0.4998 proj=1.58 | LR=0.004268\n",
            "Epoch  50 | Train: angle=0.1225 proj=1.06 | Val: angle=0.4963 proj=1.53 | LR=0.004240\n",
            "Epoch  51 | Train: angle=0.1270 proj=1.07 | Val: angle=0.4977 proj=1.55 | LR=0.004211\n",
            "Epoch  52 | Train: angle=0.1235 proj=1.06 | Val: angle=0.4962 proj=1.57 | LR=0.004183\n",
            "Epoch  53 | Train: angle=0.1261 proj=1.08 | Val: angle=0.4907 proj=1.55 | LR=0.004153\n",
            "Epoch  54 | Train: angle=0.1177 proj=1.05 | Val: angle=0.4956 proj=1.54 | LR=0.004124\n",
            "Epoch  55 | Train: angle=0.1120 proj=1.02 | Val: angle=0.4947 proj=1.53 | LR=0.004094\n",
            "Epoch  56 | Train: angle=0.1055 proj=0.98 | Val: angle=0.4860 proj=1.47 | LR=0.004063\n",
            "    ✓ Saved best model (val_angle=0.4860)\n",
            "Epoch  57 | Train: angle=0.1060 proj=0.98 | Val: angle=0.4901 proj=1.50 | LR=0.004032\n",
            "Epoch  58 | Train: angle=0.1141 proj=1.01 | Val: angle=0.4969 proj=1.52 | LR=0.004001\n",
            "Epoch  59 | Train: angle=0.1103 proj=0.99 | Val: angle=0.4863 proj=1.45 | LR=0.003969\n",
            "Epoch  60 | Train: angle=0.1062 proj=0.97 | Val: angle=0.4952 proj=1.51 | LR=0.003938\n",
            "Epoch  61 | Train: angle=0.1053 proj=0.96 | Val: angle=0.4887 proj=1.48 | LR=0.003905\n",
            "Epoch  62 | Train: angle=0.1104 proj=0.98 | Val: angle=0.4900 proj=1.50 | LR=0.003873\n",
            "Epoch  63 | Train: angle=0.1072 proj=0.96 | Val: angle=0.4900 proj=1.49 | LR=0.003840\n",
            "Epoch  64 | Train: angle=0.1012 proj=0.94 | Val: angle=0.4942 proj=1.49 | LR=0.003806\n",
            "Epoch  65 | Train: angle=0.1052 proj=0.96 | Val: angle=0.4857 proj=1.46 | LR=0.003773\n",
            "    ✓ Saved best model (val_angle=0.4857)\n",
            "Epoch  66 | Train: angle=0.0985 proj=0.93 | Val: angle=0.4846 proj=1.46 | LR=0.003739\n",
            "    ✓ Saved best model (val_angle=0.4846)\n",
            "Epoch  67 | Train: angle=0.0937 proj=0.91 | Val: angle=0.4897 proj=1.45 | LR=0.003704\n",
            "Epoch  68 | Train: angle=0.0914 proj=0.89 | Val: angle=0.4874 proj=1.43 | LR=0.003670\n",
            "Epoch  69 | Train: angle=0.0899 proj=0.88 | Val: angle=0.4879 proj=1.44 | LR=0.003635\n",
            "Epoch  70 | Train: angle=0.0925 proj=0.89 | Val: angle=0.4880 proj=1.44 | LR=0.003600\n",
            "Epoch  71 | Train: angle=0.0916 proj=0.89 | Val: angle=0.4829 proj=1.43 | LR=0.003564\n",
            "    ✓ Saved best model (val_angle=0.4829)\n",
            "Epoch  72 | Train: angle=0.0899 proj=0.87 | Val: angle=0.4852 proj=1.42 | LR=0.003529\n",
            "Epoch  73 | Train: angle=0.0927 proj=0.88 | Val: angle=0.4840 proj=1.41 | LR=0.003493\n",
            "Epoch  74 | Train: angle=0.0907 proj=0.87 | Val: angle=0.4899 proj=1.43 | LR=0.003457\n",
            "Epoch  75 | Train: angle=0.0891 proj=0.86 | Val: angle=0.4892 proj=1.42 | LR=0.003420\n",
            "Epoch  76 | Train: angle=0.0882 proj=0.85 | Val: angle=0.4867 proj=1.43 | LR=0.003384\n",
            "Epoch  77 | Train: angle=0.0889 proj=0.86 | Val: angle=0.4876 proj=1.41 | LR=0.003347\n",
            "Epoch  78 | Train: angle=0.0886 proj=0.85 | Val: angle=0.4874 proj=1.40 | LR=0.003310\n",
            "Epoch  79 | Train: angle=0.0865 proj=0.84 | Val: angle=0.4822 proj=1.39 | LR=0.003273\n",
            "    ✓ Saved best model (val_angle=0.4822)\n",
            "Epoch  80 | Train: angle=0.0947 proj=0.86 | Val: angle=0.4846 proj=1.42 | LR=0.003235\n",
            "Epoch  81 | Train: angle=0.0982 proj=0.87 | Val: angle=0.4869 proj=1.44 | LR=0.003197\n",
            "Epoch  82 | Train: angle=0.0919 proj=0.86 | Val: angle=0.4806 proj=1.41 | LR=0.003160\n",
            "    ✓ Saved best model (val_angle=0.4806)\n",
            "Epoch  83 | Train: angle=0.0847 proj=0.83 | Val: angle=0.4848 proj=1.40 | LR=0.003122\n",
            "Epoch  84 | Train: angle=0.0824 proj=0.82 | Val: angle=0.4844 proj=1.38 | LR=0.003084\n",
            "Epoch  85 | Train: angle=0.0803 proj=0.81 | Val: angle=0.4844 proj=1.40 | LR=0.003045\n",
            "Epoch  86 | Train: angle=0.0803 proj=0.80 | Val: angle=0.4851 proj=1.39 | LR=0.003007\n",
            "Epoch  87 | Train: angle=0.0823 proj=0.81 | Val: angle=0.4823 proj=1.38 | LR=0.002968\n",
            "Epoch  88 | Train: angle=0.0823 proj=0.81 | Val: angle=0.4852 proj=1.40 | LR=0.002930\n",
            "Epoch  89 | Train: angle=0.0813 proj=0.80 | Val: angle=0.4867 proj=1.40 | LR=0.002891\n",
            "Epoch  90 | Train: angle=0.0821 proj=0.81 | Val: angle=0.4890 proj=1.39 | LR=0.002852\n",
            "Epoch  91 | Train: angle=0.0858 proj=0.81 | Val: angle=0.4842 proj=1.38 | LR=0.002813\n",
            "Epoch  92 | Train: angle=0.0850 proj=0.80 | Val: angle=0.4849 proj=1.40 | LR=0.002774\n",
            "Epoch  93 | Train: angle=0.0825 proj=0.80 | Val: angle=0.4831 proj=1.38 | LR=0.002735\n",
            "Epoch  94 | Train: angle=0.0777 proj=0.78 | Val: angle=0.4832 proj=1.37 | LR=0.002696\n",
            "Epoch  95 | Train: angle=0.0745 proj=0.77 | Val: angle=0.4840 proj=1.36 | LR=0.002657\n",
            "Epoch  96 | Train: angle=0.0717 proj=0.76 | Val: angle=0.4818 proj=1.35 | LR=0.002618\n",
            "Epoch  97 | Train: angle=0.0705 proj=0.75 | Val: angle=0.4816 proj=1.37 | LR=0.002579\n",
            "Epoch  98 | Train: angle=0.0705 proj=0.75 | Val: angle=0.4825 proj=1.35 | LR=0.002539\n",
            "Epoch  99 | Train: angle=0.0697 proj=0.74 | Val: angle=0.4821 proj=1.35 | LR=0.002500\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETED\n",
            "Best validation angle: 0.4806\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "device = 'cuda:0'\n",
        "lr = 5e-3\n",
        "weight_decay = 1e-5\n",
        "num_epoch = 100\n",
        "\n",
        "model = FNO2d(modes1=modes1,\n",
        "              modes2=modes2,\n",
        "              width=width,\n",
        "              in_channel_size=in_channel_size,\n",
        "              out_size=out_size,\n",
        "              resolution=r,\n",
        "              num_layers=num_layers,\n",
        "              num_space_size=k,\n",
        "              norm=norm,\n",
        "              grid=grid,\n",
        "              COMPLEX=COMPLEX).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iterations = num_epoch * len(train_loader)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations)\n",
        "\n",
        "#! Hybrid loss\n",
        "class HybridLoss(nn.Module):\n",
        "    def __init__(self, alpha=10.0):\n",
        "        super().__init__()\n",
        "        self.proj_loss = ProjectionLoss(num_type='real', reduction='mean')\n",
        "        self.angle_loss = PrincipalAngle(angle_type='biggest', reduction='mean')\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, Q, V):\n",
        "        proj = self.proj_loss(Q, V)\n",
        "        angle = self.angle_loss(Q, V)\n",
        "        return proj + self.alpha * angle\n",
        "\n",
        "    def get_components(self, Q, V):\n",
        "        with torch.no_grad():\n",
        "            proj = self.proj_loss(Q, V).item()\n",
        "            angle = self.angle_loss(Q, V).item()\n",
        "        return proj, angle\n",
        "\n",
        "train_loss_fn = HybridLoss(alpha=10.0)\n",
        "test_loss_fn = PrincipalAngle()\n",
        "\n",
        "\n",
        "print(\"*\"*20 + \" TRAINING\" + \"*\"*20)\n",
        "print(f\"Config: width={20}, modes={12}x{12}, layers={5}\")\n",
        "print(f\"Loss: ProjectionLoss + {10.0} * AngleLoss\")\n",
        "print(f\"Data: {len(train_loader)} train batches, {len(valid_loader)} val batches\\n\")\n",
        "\n",
        "best_val_angle = float('inf')\n",
        "patience = 20\n",
        "no_improve_count = 0\n",
        "\n",
        "\n",
        "accumulation_steps = 2\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "\n",
        "    train_loss_total = 0\n",
        "    train_angle_total = 0\n",
        "    train_proj_total = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        batch_data = move_to_cuda(batch_data, device=device)\n",
        "\n",
        "        inputs = batch_data['inputs']\n",
        "        if inputs.ndim == 5:\n",
        "            inputs = inputs.squeeze(-1)\n",
        "        if inputs.shape[1] == 302 and inputs.shape[2] == 302:\n",
        "            inputs = inputs[:, 1:-1, 1:-1, :]\n",
        "\n",
        "        label = batch_data['eig_vecs']\n",
        "        output = model(**{'inputs': inputs})\n",
        "\n",
        "        loss = train_loss_fn(output, label)\n",
        "\n",
        "        loss = loss / accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            angle = test_loss_fn(output, label)\n",
        "            proj, angle_comp = train_loss_fn.get_components(output, label)\n",
        "\n",
        "            train_loss_total += loss.item() * accumulation_steps  # умножаем обратно\n",
        "            train_angle_total += angle.item()\n",
        "            train_proj_total += proj\n",
        "\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if len(train_loader) % accumulation_steps != 0:\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_train_loss = train_loss_total / len(train_loader)\n",
        "    avg_train_angle = train_angle_total / len(train_loader)\n",
        "    avg_train_proj = train_proj_total / len(train_loader)\n",
        "\n",
        "    # ============================================================\n",
        "    # VALIDATION\n",
        "    # ============================================================\n",
        "    model.eval()\n",
        "    val_angle_total = 0\n",
        "    val_proj_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data in valid_loader:\n",
        "            batch_data = move_to_cuda(batch_data, device=device)\n",
        "\n",
        "            inputs = batch_data['inputs']\n",
        "            if inputs.ndim == 5:\n",
        "                inputs = inputs.squeeze(-1)\n",
        "            if inputs.shape[1] == 302:\n",
        "                inputs = inputs[:, 1:-1, 1:-1, :]\n",
        "\n",
        "            label = batch_data['eig_vecs']\n",
        "            output = model(**{'inputs': inputs})\n",
        "\n",
        "            angle = test_loss_fn(output, label)\n",
        "            proj, _ = train_loss_fn.get_components(output, label)\n",
        "\n",
        "            val_angle_total += angle.item()\n",
        "            val_proj_total += proj\n",
        "\n",
        "    avg_val_angle = val_angle_total / len(valid_loader)\n",
        "    avg_val_proj = val_proj_total / len(valid_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:3d} | \"\n",
        "          f\"Train: angle={avg_train_angle:.4f} proj={avg_train_proj:.2f} | \"\n",
        "          f\"Val: angle={avg_val_angle:.4f} proj={avg_val_proj:.2f} | \"\n",
        "          f\"LR={scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "    if avg_val_angle < best_val_angle:\n",
        "        best_val_angle = avg_val_angle\n",
        "        no_improve_count = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_angle': avg_val_angle,\n",
        "        }, SAVE_PATH + 'best_model.pt')\n",
        "        print(f\"    ✓ Saved best model (val_angle={best_val_angle:.4f})\")\n",
        "    else:\n",
        "        no_improve_count += 1\n",
        "\n",
        "    if no_improve_count >= patience:\n",
        "        print(f\"\\n⚠️  Early stopping: no improvement for {patience} epochs\")\n",
        "        break\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"TRAINING COMPLETED\")\n",
        "print(f\"Best validation angle: {best_val_angle:.4f}\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
